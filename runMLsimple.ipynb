{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ML methods on PanPred and panta outputs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from numpy import genfromtxt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\", feature_selection = False, FS_method = 'mutual_info_classif', X2 = None):\n",
    "    # base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred'+version\n",
    "    base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred_v6'\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.system('mkdir '+ base_dir)\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 2\n",
    "    n_folds = 5\n",
    "    n_samples = y.shape[0]\n",
    "    if X2 is not None:\n",
    "        print(\"Original shape of input:\", X.shape, X2.shape)\n",
    "    for i in range(n_loops):\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "            path_dir = base_dir +'/' + data_set + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "            print('Run: ', i, ', fold: ', fold)\n",
    "            X_train = X[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "            if False:\n",
    "                if i <= 0:\n",
    "                    print(\"Run feature selection\", 'method = ', FS_method)\n",
    "                if FS_method == 'mutual_info_classif':\n",
    "                    fs_fit = SelectKBest(mutual_info_classif, k=1000).fit(X_train, y_train)\n",
    "                elif FS_method == 'chi2':\n",
    "                    fs_fit = SelectKBest(chi2, k=1000).fit(X_train, y_train)\n",
    "                else:\n",
    "                    print(\"Please input correct feature selection method\")\n",
    "                X_train = fs_fit.transform(X_train)\n",
    "                X_test = fs_fit.transform(X_test)\n",
    "            if X2 is not None:\n",
    "                X2_train = X2[train_idx]\n",
    "                X2_test = X2[test_idx]\n",
    "                if feature_selection:\n",
    "                    fs2_fit = SelectKBest(chi2, k=20000).fit(X2_train, y_train)\n",
    "                    X2_train = fs2_fit.transform(X2_train)\n",
    "                    X2_test = fs2_fit.transform(X2_test)\n",
    "                X_train = np.append(X_train, X2_train, axis = 1)\n",
    "                X_test = np.append(X_test, X2_test, axis = 1)\n",
    "              \n",
    "            # print(\"Standize the data\")\n",
    "            # Save the test true labels\n",
    "            np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "            if i <= 0 and fold <= 0:\n",
    "                print(\"n_samples: \", n_samples)\n",
    "                print(\"Reduced shape of the data: \", X_train.shape, X_test.shape)\n",
    "            print(test_idx[:10])\n",
    "            model = lgb.LGBMClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            methods.append('LightGBM')\n",
    "            print(methods[-1], end =', ')\n",
    "            # clfG.fit(X_train, y_train)\n",
    "            y_predict=model.predict(X_test) \n",
    "            np.savetxt(path_dir + \"_LightGBM_labels.csv\", y_predict, delimiter=\",\")\n",
    "            score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops*n_folds, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd9157e-b3ab-42e6-9517-ac9b931d6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_panta = pd.read_csv(\"/data/hoan/amromics/prediction/data/Ecoli1936metafiles/metadata_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54efcc1e-d9f7-46ef-b596-9660e0db5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(metadata_panta['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31dc7582-59ce-4440-9a44-cc9a4d92a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_mat = np.load('/data/hoan/amromics/prediction/data/kmer_full_mat_VT1_DNA.npy') # pantaDifferSite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06729c27-a793-4207-baeb-9bf07f73d528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 287260)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d57cc4-21fb-4cf5-b0c8-b1662cda0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41458834/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated\n",
    "## No _ in the method name, please\n",
    "from pangraph.utils import binary_label\n",
    "max_idx_amr = 14; # max value = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd563768-2443-4f0c-8032-e48f5590ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 3):\n",
    "for idx in range(2, max_idx_amr):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    # y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))]) version _v5\n",
    "    y, nonenan_index = binary_label(y_class) # v6\n",
    "    # pa_matrix_new = pa_matrix[nonenan_index, ]\n",
    "    y_new = y[nonenan_index]\n",
    "    snp_mat_new = snp_mat[nonenan_index,]\n",
    "    # Run unimodal gene\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(full_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(snp_mat, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaSnp', True, 'chi2')\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombine', False, 'mutual_info_classif', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombineScale', True, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombinehighGene', False, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'chi2', None)\n",
    "    # run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaVT10', False, 'chi2', None)\n",
    "    # run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_single, False, 'chi2', None)\n",
    "    run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], \"KmerK31DNA\", False, 'chi2', None)\n",
    "    # run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_combine, False, 'chi2', snp_mat_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
