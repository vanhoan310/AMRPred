{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45edcb50-b448-4279-a5f7-c00c5a5beb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from numpy import genfromtxt\n",
    "# from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import gzip\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cad8dd-6ece-488a-ae3b-518155dc7e47",
   "metadata": {},
   "source": [
    "### Create map from gene ID to cluster ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a71e3aa-b691-4993-a1f2-913b36c1c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panta input directory\n",
    "# pantain_dir = '/data/hoan/amromics/prediction/data/Ecoli1936/prokkatest/'\n",
    "pantain_dir = '/data/hoan/amromics/prediction/data/Ecoli1936/prokka/'\n",
    "# panta output dir\n",
    "# pantaout_dir = '/data/hoan/amromics/prediction/output/pantaEcoli1936aligntest/'\n",
    "pantaout_dir = '/data/hoan/amromics/prediction/output/pantaEcoli1936align_v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e0db2a-0ad9-4b01-a50e-da730f189332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pantaout_dir + 'annotated_clusters.json', 'r') as JSON:\n",
    "    json_dict = json.load(JSON)\n",
    "# data = json.loads('/data/hoan/amromics/prediction/output/pantaEcoli1936aligntest/clusters.json')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70593154-9504-415e-9488-de6e390c41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf6c756-0fc8-4287-a781-7ec1c2d6962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2clusterdict = {}\n",
    "for key in json_dict:\n",
    "    if len(json_dict[key])==0:\n",
    "        gene2clusterdict[key] = key\n",
    "    for gene in json_dict[key]['gene_id']:\n",
    "        gene2clusterdict[gene] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c042bc-0bb1-4f8b-8af3-c45f85ff6fd0",
   "metadata": {},
   "source": [
    "### Find all AMR genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72aaf11-5805-4066-a9dc-86e11cdf49b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_gff_AMRgene_finder(gff_fh, sample_id, min_protein_len=40):\n",
    "    # gene_annotation = OrderedDict()\n",
    "    # gene_position = OrderedDict()    \n",
    "    # suffix = 1\n",
    "    # bed_records = []\n",
    "    # gene_index = 0\n",
    "    seq_id = None\n",
    "    min_cds_len = 3 * min_protein_len\n",
    "    gene_list = []\n",
    "    \n",
    "    for line in gff_fh:            \n",
    "        if line.startswith('##FASTA'):\n",
    "            #Done reading gff, move on to reading fasta\n",
    "            break\n",
    "\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        cells = line.split('\\t')\n",
    "        if cells[2] != 'CDS':\n",
    "            continue\n",
    "        if 'BARRGD' not in cells[8]:\n",
    "            continue\n",
    "        start = int(cells[3])\n",
    "        end = int(cells[4])\n",
    "        length = end - start + 1\n",
    "        if length < min_cds_len:\n",
    "            continue\n",
    "        if length % 3 != 0:\n",
    "            continue\n",
    "        cells[0] = cells[0].replace('-','_') #make sure seq_id has no -\n",
    "        \n",
    "        if seq_id != cells[0]:\n",
    "            seq_id = cells[0]\n",
    "            gene_index = 0\n",
    "\n",
    "        # strand = cells[6]\n",
    "        tags = cells[8].split(';')\n",
    "        gene_id = None\n",
    "        gene_name = ''\n",
    "        gene_product = ''\n",
    "        for tag in tags:\n",
    "            if tag.startswith('ID='):\n",
    "                gene_id = tag[3:]\n",
    "            elif tag.startswith('gene='):                    \n",
    "                gene_name = tag[5:]\n",
    "                gene_name = re.sub(r'\\W', '_', gene_name)\n",
    "            elif tag.startswith('product='):                    \n",
    "                gene_product = tag[8:]\n",
    "        if gene_id == None:\n",
    "            continue\n",
    "\n",
    "        # Ensure gene_id is in the format of sample_id-seq_id-gene_tag\n",
    "        if not gene_id.startswith(sample_id + '-'):\n",
    "            gene_id = sample_id + '-' + gene_id\n",
    "\n",
    "        if not gene_id.startswith(sample_id + '-' + seq_id + '-'):\n",
    "            gene_id = sample_id + '-' + seq_id + '-' + gene_id[len(sample_id)+1:]\n",
    "\n",
    "        gene_list.append(gene_id)\n",
    "    \n",
    "    return gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206c1509-139b-4d43-bfd0-848ed518e695",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def parse_alignment(gff_fh):\n",
    "#     sample_list = []\n",
    "#     seq_list = []\n",
    "#     index = 0\n",
    "#     for line in gff_fh:            \n",
    "#         if line[0] == '>':\n",
    "#             if index >= 1:\n",
    "#                 seq_list.append(seq)\n",
    "#             index+=1\n",
    "#             sample_list.append(line.split('-')[0][1:])\n",
    "#             seq = ''\n",
    "#         else:\n",
    "#             seq += line[:-1]\n",
    "#             # seq_list.append(line)\n",
    "#     seq_list.append(seq)\n",
    "#     return sample_list, seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5175a6b-93bf-428e-9cdf-e30dc0f7af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_gene = []\n",
    "for data_dir in glob.glob(pantain_dir + '*.gff'):\n",
    "    # print(data_dir)\n",
    "    in_fh = open(data_dir)\n",
    "    sample_id = data_dir.split('/')[-1][:-4]\n",
    "    amr_gene += parse_gff_AMRgene_finder(in_fh, sample_id)\n",
    "    in_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa7525a-448d-4f50-952d-33c23165b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SAMEA2204230.contig-SAMEA2204230.contig00001-KJJADFBE_00063',\n",
       "  'SAMEA2204230.contig-SAMEA2204230.contig00001-KJJADFBE_00095',\n",
       "  'SAMEA2204230.contig-SAMEA2204230.contig00001-KJJADFBE_00151'],\n",
       " 119509)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr_gene[:3], len(amr_gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8c095d-51f2-4113-b474-baeaadeb76d0",
   "metadata": {},
   "source": [
    "## TODO: Map genes back to cluster IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f1c9b1-de33-42d5-816b-9eecc858e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_clusterID = [gene2clusterdict[gene] for gene in amr_gene]\n",
    "amr_clusterID = list(set(amr_clusterID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc565bb9-4d81-4722-9c17-31d93e7e9b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amr_clusterID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86127ffc-5a40-452b-b6e4-877470dd03d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute label encoder for AMR cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2bcb5c-422a-4c9e-9d07-e39d5a7d800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pantaout_dir + 'samples.json', 'r') as JSON:\n",
    "    sample_dict = json.load(JSON)\n",
    "sample2integerindex = {}\n",
    "for idx in range(len(sample_dict)):\n",
    "    sample2integerindex[sample_dict[idx]['id']] = idx\n",
    "n_samples = len(sample_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f93f77a-5a8a-4065-86df-9fe8a6fc04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample2integerindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5834bd5a-85db-45a8-86ac-183807acde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "#          'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(codes)\n",
    "# le.transform(['-', 'P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1c50df-7cab-44a3-a025-78038c1bfec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-fb2a261be462>\", line 29, in <module>\n",
      "    mat[sample2integerindex[sample_id],:] = 1 + le.transform([*sequence])\n",
      "  File \"/home/vanhoan310/.local/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\", line 138, in transform\n",
      "    return _encode(y, uniques=self.classes_)\n",
      "  File \"/home/vanhoan310/.local/lib/python3.6/site-packages/sklearn/utils/_encode.py\", line 178, in _encode\n",
      "    return _map_to_integer(values, uniques)\n",
      "  File \"/home/vanhoan310/.local/lib/python3.6/site-packages/sklearn/utils/_encode.py\", line 122, in _map_to_integer\n",
      "    table = _nandict({val: i for i, val in enumerate(uniques)})\n",
      "  File \"/home/vanhoan310/.local/lib/python3.6/site-packages/sklearn/utils/_encode.py\", line 110, in __init__\n",
      "    if is_scalar_nan(key):\n",
      "  File \"/home/vanhoan310/.local/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 985, in is_scalar_nan\n",
      "    return bool(isinstance(x, numbers.Real) and np.isnan(x))\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/abc.py\", line 190, in __instancecheck__\n",
      "    subclass in cls._abc_negative_cache):\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/_weakrefset.py\", line 70, in __contains__\n",
      "    def __contains__(self, item):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/tokenize.py\", line 454, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/tokenize.py\", line 423, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/home/vanhoan310/miniconda3/envs/py36/lib/python3.6/tokenize.py\", line 381, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "amr_mat = None;\n",
    "start_idx = [0];\n",
    "# end_idx = [];\n",
    "for idx in range(len(amr_clusterID)):\n",
    "    alignment_dir = pantaout_dir + 'clusters/' + amr_clusterID[idx] +'/'+amr_clusterID[idx]+'.faa.aln.gz'\n",
    "    # https://www.biostars.org/p/710/\n",
    "    # fasta_sequences = SeqIO.parse(open(alignment_dir),'fasta')\n",
    "    # for fasta in fasta_sequences:\n",
    "    #     name, sequence = fasta.id, str(fasta.seq)\n",
    "    #     print(name)\n",
    "    #     print(sequence)\n",
    "    codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "             'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(codes)\n",
    "    mat = None\n",
    "    index = 0\n",
    "    index_set = []\n",
    "    with gzip.open(alignment_dir, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            name, sequence = record.id, str(record.seq)\n",
    "            sample_id = name.split('-')[0]\n",
    "            # print(name)\n",
    "            # print(sequence)\n",
    "            # print(1 + le.transform([*sequence]))\n",
    "            if index == 0:\n",
    "                mat = np.zeros((n_samples, len(sequence)))\n",
    "            index += 1\n",
    "            mat[sample2integerindex[sample_id],:] = 1 + le.transform([*sequence])\n",
    "            index_set.append(sample2integerindex[sample_id])\n",
    "            # print(record.id)\n",
    "    if idx==0:\n",
    "        amr_mat = mat\n",
    "    else:\n",
    "        # ## Run feature selection\n",
    "        variant_thres = 0.1\n",
    "        vs = True\n",
    "        if len(index_set) >= int(n_samples*0.01):\n",
    "            try:\n",
    "                sel = VarianceThreshold(variant_thres)\n",
    "                sel.fit(mat[index_set,:])\n",
    "            except ValueError:\n",
    "                vs = False\n",
    "            if vs:\n",
    "                mat = mat[:, sel.variances_>variant_thres]\n",
    "                if mat.shape[0] > 0:\n",
    "                    start_idx += [start_idx[-1] + mat.shape[1]]\n",
    "                    amr_mat = np.append(amr_mat, mat, axis=1)\n",
    "end_idx = start_idx[1:]\n",
    "start_idx = start_idx[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa23580-1bda-42bd-8168-3e506f55e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d597abf-8cee-42f2-9a59-9f6046e2d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_idx), len(end_idx), len(amr_clusterID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b83a41-0320-4347-9fdc-feaf7460374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amrgene_annotation = pd.DataFrame({'gene': amr_clusterID, 'start_index': start_idx, 'end_index': end_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107077b-1dce-400c-8938-2322bd675620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amrgene_annotation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c75afd-96aa-446a-ae97-01a8751b2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amrgene_annotation.to_csv(pantaout_dir + 'amrgene_annotation_VarianceThreshold.csv', index=None)\n",
    "# amrgene_annotation.to_csv(pantaout_dir + 'amrgene_annotation.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc1601-8675-4455-9fda-9a75178e082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(amr_mat).to_csv(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cb4ce-a891-4e2d-96ca-34f05f1ab327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amrtest = pd.read_csv(pantaout_dir + 'amrlabelencodermat.csv')\n",
    "# np.save(pantaout_dir + 'amrlabelencodermat.npy', amrtest.values) # save numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899f0cf-94d4-4133-8f34-749274169949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amrtest.values[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2c9b3-6167-4b45-994f-a412bc9c8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full matrix shape: (1653, 174005)\n",
    "# amr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf65041-2b82-4920-a7eb-a16490e7a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.npy', amr_mat) # save numpy array\n",
    "np.save(pantaout_dir + 'amrlabelencodermat_VT10.npy', amr_mat) # save numpy array\n",
    "# np.save(pantaout_dir + 'amrlabelencodermat.npy', amr_mat) # save numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79335172-4b9b-41ea-98f5-413e1c630cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0f94e-550b-4529-ab23-95c4b20db089",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1 = np.random.normal(loc=0, scale=.1, size=100) # normal dist. with mean=0 and std=.1\n",
    "feat2 = np.random.normal(loc=0, scale=10, size=100) # normal dist. with mean=0 and std=10\n",
    "feat3 = np.random.uniform(low=0, high=10, size=100) # uniform dist. in the interval [0,10)\n",
    "data = np.column_stack((feat1,feat2,feat3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae972fac-ebbe-4e9e-b7f0-f569ad7eae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c45af-9003-4953-9b67-363a5699204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(0)\n",
    "selector.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4ad41-efdb-4100-b79c-7ff5c22fbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.variant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9716f9-1202-47ab-a90e-78ffc748c50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
