{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ML methods on PanPred and panta outputs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28dc2ebc-ed87-4fa2-b5e2-6a87ad16059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbab2fdc-821c-4a48-9fd9-982cc7ddfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\"):\n",
    "    base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred'+version\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.system('mkdir '+ base_dir)\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 5\n",
    "    n_samples = y.shape[0]\n",
    "    for i in range(n_loops):\n",
    "        path_dir = base_dir +'/' + data_set + '_run_'+str(i)+'_'+approach\n",
    "        print('Run: ', i)\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        # print(X_train.shape, X_test.shape)\n",
    "        random.seed(i)\n",
    "        train_idx = random.sample(range(n_samples), int(n_samples*0.8))\n",
    "        test_idx = [i for i in range(n_samples) if i not in train_idx]\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test = y[test_idx]\n",
    "        # Save the test true labels\n",
    "        np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "        if i <= 0:\n",
    "            print(\"n_samples: \", n_samples)\n",
    "            print(X_train.shape, X_test.shape)\n",
    "        print(train_idx[:10])\n",
    "        \n",
    "        # SVM\n",
    "        methods.append('SVM')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        np.savetxt(path_dir + \"_SVM_labels.csv\", y_predict, delimiter=\",\")\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "       \n",
    "        # Decision Tree\n",
    "        methods.append('Decision Tree')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_DecisionTree_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # RF\n",
    "        methods.append('RF')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        np.savetxt(path_dir + \"_RandomForest_labels.csv\", y_predict, delimiter=\",\")\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # # Neural network\n",
    "        # methods.append('Neural network')\n",
    "        # print(methods[-1], end =', ')\n",
    "        # clf = MLPClassifier(alpha=1, max_iter=2000).fit(X_train, y_train)\n",
    "        # y_predict = clf.predict(X_test)\n",
    "        # np.savetxt(path_dir + \"_NeuralNet_labels.csv\", y_predict, delimiter=\",\")\n",
    "        # score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # Adaboost\n",
    "        methods.append('Adaboost')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_Adaboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # GradientBoostingClassifier\n",
    "        methods.append('Gradient Boost Decision Tree')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_GBDT_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "#         ## K-NN \n",
    "#         methods.append('kNN')\n",
    "#         print(methods[-1], end =', ')\n",
    "#         clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "#         np.savetxt(path_dir + \"_NearestNeighbors_labels.csv\", y_predict, delimiter=\",\")\n",
    "#         y_predict = clf.predict(X_test)\n",
    "#         score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "#         # Naive Bayes\n",
    "#         methods.append('NaiveBayes')\n",
    "#         print(methods[-1], end ='\\n')\n",
    "#         clf = GaussianNB().fit(X_train, y_train)\n",
    "#         np.savetxt(path_dir + \"_NaiveBayes_labels.csv\", y_predict, delimiter=\",\")\n",
    "#         y_predict = clf.predict(X_test)\n",
    "#         score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fad6e7-89f3-4c66-97b8-d15a2c7cf662",
   "metadata": {},
   "source": [
    "### Run PanPred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d4104a-03fe-4ab7-883b-2923866b7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata = pd.read_csv(\"PanPred/test_data/gene_presence_absence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a41d179-2646-4232-86a0-5a0a4b32a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2571b1ac-3dba-4fc9-bc8c-4386a58887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('PanPred/test_data/Metadata.csv')\n",
    "metadata = metadata.set_index(metadata['Isolate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18176ab1-dda8-4689-8c07-fd19c3d0be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8655ff5-829c-40dc-826a-b32623e25793",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessorygene =  pd.read_csv('PanPred/test_data/AccessoryGene.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f422a3b0-148b-476d-b784-c26aba46061a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yeiU</th>\n",
       "      <th>yhhS</th>\n",
       "      <th>ybaE</th>\n",
       "      <th>eutR</th>\n",
       "      <th>ibrB</th>\n",
       "      <th>ytfP</th>\n",
       "      <th>aslB</th>\n",
       "      <th>narQ</th>\n",
       "      <th>tolR</th>\n",
       "      <th>galM</th>\n",
       "      <th>...</th>\n",
       "      <th>group_48768</th>\n",
       "      <th>group_48873</th>\n",
       "      <th>group_48916</th>\n",
       "      <th>group_48933</th>\n",
       "      <th>group_48937</th>\n",
       "      <th>group_48958</th>\n",
       "      <th>group_49020</th>\n",
       "      <th>group_49174</th>\n",
       "      <th>group_49253</th>\n",
       "      <th>group_49257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11657_5#1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657_5#10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 17198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            yeiU  yhhS  ybaE  eutR  ibrB  ytfP  aslB  narQ  tolR  galM  ...  \\\n",
       "11657_5#1      1     1     1     1     1     1     1     1     1     1  ...   \n",
       "11657_5#10     1     1     1     1     1     1     1     1     1     1  ...   \n",
       "\n",
       "            group_48768  group_48873  group_48916  group_48933  group_48937  \\\n",
       "11657_5#1             0            0            0            0            0   \n",
       "11657_5#10            0            0            0            0            0   \n",
       "\n",
       "            group_48958  group_49020  group_49174  group_49253  group_49257  \n",
       "11657_5#1             0            0            0            0            0  \n",
       "11657_5#10            0            0            0            0            0  \n",
       "\n",
       "[2 rows x 17198 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accessorygene.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3195e2c-6081-47ee-8836-1aff8ae07b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationstructure =  pd.read_csv('PanPred/test_data/PopulationStructure.csv_labelencoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8914f2ff-bf45-4c08-899f-f86867a79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accessorygene = accessorygene.loc[metadata['Isolate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da59d-d9be-433d-b3ae-1f99d0b1a15e",
   "metadata": {},
   "source": [
    "#### Run ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f790cd83-c663-4b27-b7a5-5c595f5115f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 14):\n",
    "#     y_class = metadata.iloc[:,idx].values\n",
    "#     print(metadata.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(1936)])\n",
    "#     run_ML(new_accessorygene.values, y, 'Ecoli1936','classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b18095a-41a5-47af-914b-b9028d944f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_accessorygene.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1ceff-dcc1-4f68-b5d8-709974fe9197",
   "metadata": {},
   "source": [
    "### Run Panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5586647a-797e-49e9-9b25-66a0f4af3a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f93627-ebe5-4473-8e81-59e3dd0de1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_isolate = pd.read_csv('/data/hoan/amromics/prediction/data/Ecoli1936metafiles/sample_isolate.csv')\n",
    "sample_isolate.head(2)\n",
    "sample2isolate = {}\n",
    "for idx in range(len(sample_isolate.index)):\n",
    "    sample2isolate[sample_isolate.iloc[idx,0]+'.contig'] = sample_isolate.iloc[idx,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae607ee-2625-4af8-85e0-d16f8a5fe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936/gene_presence_absence.Rtab', sep='\\t', index_col=0).T\n",
    "pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936align'+version+'/gene_presence_absence.Rtab', sep='\\t', index_col=0).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5722d248-26dd-4b27-8d25-34f685ef6cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gene</th>\n",
       "      <th>groups_0</th>\n",
       "      <th>namA</th>\n",
       "      <th>groups_2</th>\n",
       "      <th>groups_3</th>\n",
       "      <th>groups_4</th>\n",
       "      <th>groups_5</th>\n",
       "      <th>groups_6</th>\n",
       "      <th>groups_7</th>\n",
       "      <th>groups_8</th>\n",
       "      <th>groups_9</th>\n",
       "      <th>...</th>\n",
       "      <th>groups_74779</th>\n",
       "      <th>groups_74780</th>\n",
       "      <th>groups_74781</th>\n",
       "      <th>groups_74782</th>\n",
       "      <th>traI_2_16929</th>\n",
       "      <th>groups_74784</th>\n",
       "      <th>groups_74785</th>\n",
       "      <th>groups_74786</th>\n",
       "      <th>groups_74787</th>\n",
       "      <th>groups_74788</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAMEA2204229.contig</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA2204230.contig</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 74789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Gene                 groups_0  namA  groups_2  groups_3  groups_4  groups_5  \\\n",
       "SAMEA2204229.contig         1     0         0         0         0         0   \n",
       "SAMEA2204230.contig         0     0         0         0         0         0   \n",
       "\n",
       "Gene                 groups_6  groups_7  groups_8  groups_9  ...  \\\n",
       "SAMEA2204229.contig         0         0         0         0  ...   \n",
       "SAMEA2204230.contig         0         0         0         0  ...   \n",
       "\n",
       "Gene                 groups_74779  groups_74780  groups_74781  groups_74782  \\\n",
       "SAMEA2204229.contig             0             0             0             0   \n",
       "SAMEA2204230.contig             0             0             0             0   \n",
       "\n",
       "Gene                 traI_2_16929  groups_74784  groups_74785  groups_74786  \\\n",
       "SAMEA2204229.contig             0             0             0             0   \n",
       "SAMEA2204230.contig             0             0             0             0   \n",
       "\n",
       "Gene                 groups_74787  groups_74788  \n",
       "SAMEA2204229.contig             0             0  \n",
       "SAMEA2204230.contig             0             0  \n",
       "\n",
       "[2 rows x 74789 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dda808e-c35e-4310-8e64-890e45d76b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 74789)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ff349f0-2a44-45c2-9055-7e347feec5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_index = [sample2isolate[sample] for sample in pa_matrix.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69cc2db8-11c4-47e6-96e8-90f245a58891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd3f2b9-3ce4-4afc-a94b-44217a14c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_panta = metadata.loc[isolate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "135120f7-251d-478a-a458-3c9fd23c52c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate</th>\n",
       "      <th>Year</th>\n",
       "      <th>CTZ</th>\n",
       "      <th>CTX</th>\n",
       "      <th>AMP</th>\n",
       "      <th>AMX</th>\n",
       "      <th>AMC</th>\n",
       "      <th>TZP</th>\n",
       "      <th>CXM</th>\n",
       "      <th>CET</th>\n",
       "      <th>GEN</th>\n",
       "      <th>TBM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>CIP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isolate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11658_4#1</th>\n",
       "      <td>11658_4#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657_5#1</th>\n",
       "      <td>11657_5#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658_4#2</th>\n",
       "      <td>11658_4#2</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658_5#1</th>\n",
       "      <td>11658_5#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658_5#2</th>\n",
       "      <td>11658_5#2</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090_6#61</th>\n",
       "      <td>18090_6#61</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090_8#30</th>\n",
       "      <td>18090_8#30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090_6#63</th>\n",
       "      <td>18090_6#63</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090_8#33</th>\n",
       "      <td>18090_8#33</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090_8#84</th>\n",
       "      <td>18090_8#84</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1653 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Isolate    Year CTZ CTX AMP  AMX AMC TZP CXM CET GEN TBM TMP  \\\n",
       "Isolate                                                                       \n",
       "11658_4#1    11658_4#1  2006.0   S   S   S  NaN   S   S   R   S   S   S   S   \n",
       "11657_5#1    11657_5#1  2006.0   S   S   R  NaN   R   S   S   S   S   S   R   \n",
       "11658_4#2    11658_4#2  2006.0   S   S   S  NaN   S   S   S   S   S   S   S   \n",
       "11658_5#1    11658_5#1  2006.0   S   S   R  NaN   S   S   S   S   S   S   R   \n",
       "11658_5#2    11658_5#2  2007.0   S   R   R  NaN   R   S   R   R   S   R   R   \n",
       "...                ...     ...  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "18090_6#61  18090_6#61  2015.0   R   R   R  NaN   S   S   R   R   R   R   S   \n",
       "18090_8#30  18090_8#30  2015.0   S   R   R  NaN   S   S   R   R   R   R   R   \n",
       "18090_6#63  18090_6#63  2015.0   S   R   R  NaN   S   S   R   R   R   R   R   \n",
       "18090_8#33  18090_8#33  2015.0   S   R   R  NaN   R   S   R   R   R   R   S   \n",
       "18090_8#84  18090_8#84  2015.0   S   R   R  NaN   S   S   R   R   S   S   S   \n",
       "\n",
       "           CIP  \n",
       "Isolate         \n",
       "11658_4#1    S  \n",
       "11657_5#1    R  \n",
       "11658_4#2    S  \n",
       "11658_5#1    R  \n",
       "11658_5#2    R  \n",
       "...         ..  \n",
       "18090_6#61   S  \n",
       "18090_8#30   S  \n",
       "18090_6#63   R  \n",
       "18090_8#33   S  \n",
       "18090_8#84   S  \n",
       "\n",
       "[1653 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d1b347c-ee64-4675-8b93-afa8322a00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTZ\n",
      "Run:  0\n",
      "n_samples:  1653\n",
      "(1322, 74789) (331, 74789)\n",
      "[788, 1552, 861, 82, 530, 1047, 995, 829, 1605, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/hoan/mybin/miniconda3/envs/py36/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6d179f4af8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_panta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'R'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrun_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ecoli1936'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetadata_panta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'panta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-9b54b0660ea9>\u001b[0m in \u001b[0;36mrun_ML\u001b[0;34m(X, y, data_set, approach)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adaboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_Adaboost_labels.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \"\"\"\n\u001b[1;32m    934\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0;32m--> 408\u001b[0;31m                                     reset=False)\n\u001b[0m\u001b[1;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    410\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(2, 14):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "    run_ML(pa_matrix.values, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'panta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7461afdd-42e9-4d26-b4a5-39235592fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTZ\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.49 0.74 0.5  0.68 0.72 0.5  0.5 ]\n",
      "CTX\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.73 0.8  0.49 0.86 0.83 0.63 0.56]\n",
      "AMP\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.7  0.72 0.39 0.71 0.73 0.65 0.56]\n",
      "AMX\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.67 0.66 0.44 0.6  0.6  0.47 0.55]\n",
      "AMC\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.68 0.69 0.41 0.72 0.65 0.53 0.56]\n",
      "TZP\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.51 0.5  0.49 0.51 0.49 0.49 0.48]\n",
      "CXM\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.69 0.67 0.47 0.75 0.64 0.64 0.56]\n",
      "CET\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.65 0.73 0.48 0.69 0.74 0.62 0.51]\n",
      "GEN\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.66 0.92 0.48 0.93 0.94 0.48 0.57]\n",
      "TBM\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.75 0.91 0.48 0.85 0.71 0.69 0.48]\n",
      "TMP\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.73 0.76 0.44 0.71 0.75 0.64 0.58]\n",
      "CIP\n",
      "Run:  0\n",
      "n_samples:  667\n",
      "(533, 17198) (134, 17198)\n",
      "[394, 430, 41, 265, 523, 497, 414, 310, 488, 366]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  1\n",
      "[137, 582, 64, 261, 120, 507, 460, 483, 388, 214]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  2\n",
      "[57, 93, 86, 369, 173, 315, 257, 620, 217, 621]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  3\n",
      "[243, 606, 557, 133, 378, 618, 485, 640, 594, 67]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "Run:  4\n",
      "[241, 310, 105, 405, 490, 158, 92, 68, 20, 411]\n",
      "SVM, Decision Tree, RF, Adaboost, Gradient Boost Decision Tree, kNN, NaiveBayes\n",
      "['SVM', 'Decision Tree', 'RF', 'Adaboost', 'Gradient Boost Decision Tree', 'kNN', 'NaiveBayes']\n",
      "[0.88 0.79 0.46 0.84 0.81 0.8  0.76]\n"
     ]
    }
   ],
   "source": [
    "## Run PanPred on panta isolate\n",
    "pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "for idx in range(2, 14):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "    run_ML(pa_matrixPanPred.values, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cdf150f-1771-4fd0-8858-e4acd2a6f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_matrixPanPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffc6f1bb-c89f-4f57-a880-045a03cbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b84256-8884-4bbf-bdef-d88a554efb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
