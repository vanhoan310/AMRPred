{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ML methods on PanPred and panta outputs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from numpy import genfromtxt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbab2fdc-821c-4a48-9fd9-982cc7ddfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '_v5'  # Run feature selection\n",
    "## Label: R: for resistance, the remaining labels (I, S, missing) is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\", feature_selection = False, FS_method = 'mutual_info_classif', X2 = None):\n",
    "    base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred'+version\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.system('mkdir '+ base_dir)\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 2\n",
    "    n_folds = 5\n",
    "    n_samples = y.shape[0]\n",
    "    if X2 is not None:\n",
    "        print(\"Original shape of input:\", X.shape, X2.shape)\n",
    "    for i in range(n_loops):\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "            path_dir = base_dir +'/' + data_set + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "            print('Run: ', i, ', fold: ', fold)\n",
    "            X_train = X[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "            if False:\n",
    "                if i <= 0:\n",
    "                    print(\"Run feature selection\", 'method = ', FS_method)\n",
    "                if FS_method == 'mutual_info_classif':\n",
    "                    fs_fit = SelectKBest(mutual_info_classif, k=1000).fit(X_train, y_train)\n",
    "                elif FS_method == 'chi2':\n",
    "                    fs_fit = SelectKBest(chi2, k=1000).fit(X_train, y_train)\n",
    "                else:\n",
    "                    print(\"Please input correct feature selection method\")\n",
    "                X_train = fs_fit.transform(X_train)\n",
    "                X_test = fs_fit.transform(X_test)\n",
    "            if X2 is not None:\n",
    "                X2_train = X2[train_idx]\n",
    "                X2_test = X2[test_idx]\n",
    "                if feature_selection:\n",
    "                    fs2_fit = SelectKBest(chi2, k=20000).fit(X2_train, y_train)\n",
    "                    X2_train = fs2_fit.transform(X2_train)\n",
    "                    X2_test = fs2_fit.transform(X2_test)\n",
    "                X_train = np.append(X_train, X2_train, axis = 1)\n",
    "                X_test = np.append(X_test, X2_test, axis = 1)\n",
    "                # print('Scale the combine data')\n",
    "                # scaler = StandardScaler()\n",
    "                # X_train = scaler.fit_transform(X_train)\n",
    "                # X_test = scaler.fit_transform(X_test)\n",
    "                \n",
    "            # print(\"Standize the data\")\n",
    "            # Save the test true labels\n",
    "            np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "            if i <= 0 and fold <= 0:\n",
    "                print(\"n_samples: \", n_samples)\n",
    "                print(\"Reduced shape of the data: \", X_train.shape, X_test.shape)\n",
    "            print(test_idx[:10])\n",
    "\n",
    "#             # SVM\n",
    "#             methods.append('SVM')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_SVM_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Decision Tree\n",
    "#             methods.append('Decision Tree')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_DecisionTree_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # RF\n",
    "#             methods.append('RF')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_RandomForest_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Neural network\n",
    "#             methods.append('Neural network')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = MLPClassifier(alpha=1, max_iter=2000).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NeuralNet_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Adaboost\n",
    "#             methods.append('Adaboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Adaboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             ## K-NN \n",
    "#             methods.append('kNN')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NearestNeighbors_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Naive Bayes\n",
    "#             methods.append('NaiveBayes')\n",
    "#             print(methods[-1], end ='\\n')\n",
    "#             clf = GaussianNB().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NaiveBayes_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "   \n",
    "#             # Xgboost\n",
    "#             clf=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=500, objective='binary:logistic', booster='gbtree', use_label_encoder=False) #binary\n",
    "#             methods.append('Xgboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             XGB=clf.fit(X_train,y_train)\n",
    "#             y_predict=XGB.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Xgboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "            \n",
    "            # # GradientBoostingClassifier\n",
    "            # methods.append('Gradient Boost Decision Tree')\n",
    "            # print(methods[-1], end =', ')\n",
    "            # clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "            # y_predict = clf.predict(X_test)\n",
    "            # np.savetxt(path_dir + \"_GBDT_labels.csv\", y_predict, delimiter=\",\")\n",
    "            # score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "                  \n",
    "            # LightGBM\n",
    "            # if X2 is None:\n",
    "            #     clfG = lgb.LGBMClassifier()\n",
    "            # else:\n",
    "            #     clfG = lgb.LGBMClassifier(categorical_feature=list(range(1000,1000+10000)))\n",
    "            model = lgb.LGBMClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            methods.append('LightGBM')\n",
    "            print(methods[-1], end =', ')\n",
    "            # clfG.fit(X_train, y_train)\n",
    "            y_predict=model.predict(X_test) \n",
    "            np.savetxt(path_dir + \"_LightGBM_labels.csv\", y_predict, delimiter=\",\")\n",
    "            score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops*n_folds, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fad6e7-89f3-4c66-97b8-d15a2c7cf662",
   "metadata": {},
   "source": [
    "### Run PanPred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d4104a-03fe-4ab7-883b-2923866b7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata = pd.read_csv(\"PanPred/test_data/gene_presence_absence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2571b1ac-3dba-4fc9-bc8c-4386a58887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('PanPred/test_data/Metadata.csv')\n",
    "metadata = metadata.set_index(metadata['Isolate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8655ff5-829c-40dc-826a-b32623e25793",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessorygene =  pd.read_csv('PanPred/test_data/AccessoryGene.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9787bd8-54c7-4fbc-9bcd-d65b7cb12bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationstructure =  pd.read_csv('PanPred/test_data/PopulationStructure.csv_labelencoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8914f2ff-bf45-4c08-899f-f86867a79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accessorygene = accessorygene.loc[metadata['Isolate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da59d-d9be-433d-b3ae-1f99d0b1a15e",
   "metadata": {},
   "source": [
    "#### Run ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f790cd83-c663-4b27-b7a5-5c595f5115f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 14):\n",
    "#     y_class = metadata.iloc[:,idx].values\n",
    "#     print(metadata.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(1936)])\n",
    "#     run_ML(new_accessorygene.values, y, 'Ecoli1936','classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b18095a-41a5-47af-914b-b9028d944f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_accessorygene.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1ceff-dcc1-4f68-b5d8-709974fe9197",
   "metadata": {},
   "source": [
    "### Run Panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f93627-ebe5-4473-8e81-59e3dd0de1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_isolate = pd.read_csv('/data/hoan/amromics/prediction/data/Ecoli1936metafiles/sample_isolate.csv')\n",
    "sample_isolate.head(2)\n",
    "sample2isolate = {}\n",
    "for idx in range(len(sample_isolate.index)):\n",
    "    sample2isolate[sample_isolate.iloc[idx,0]+'.contig'] = sample_isolate.iloc[idx,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae607ee-2625-4af8-85e0-d16f8a5fe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936/gene_presence_absence.Rtab', sep='\\t', index_col=0).T\n",
    "pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936align_v4/gene_presence_absence.Rtab', sep='\\t', index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177913ea-ffd9-4ff0-aef7-d2827682908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_index = [sample2isolate[sample] for sample in pa_matrix.index]\n",
    "metadata_panta = metadata.loc[isolate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a98619a-6ee4-4c4f-854e-7fe64f07d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54efcc1e-d9f7-46ef-b596-9660e0db5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(metadata_panta['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320278fc-6f12-42e8-982e-fc3af581b212",
   "metadata": {},
   "source": [
    "#### FS for presence-absence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644dd41c-b535-4f86-855d-9179d6ffe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "pa_matrix = sel.fit_transform(pa_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61843353-309e-401a-a0bf-5cd73ba7bf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 73473)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0943400b-d70e-45e9-a2cf-aedc65c12f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pantaout_dir = '/data/hoan/amromics/prediction/output/pantaEcoli1936align_v4/'\n",
    "# snp_mat = pd.read_csv(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.csv')\n",
    "# snp_mat = genfromtxt(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.csv', delimiter=',')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.npy')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat.npy')\n",
    "snp_mat = np.load(pantaout_dir + 'highDegreeGenesEncodermat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e69ca2-7ff4-4c7b-9fda-6647fdd7e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 275081)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_mat.shape\n",
    "# full_matrix =  np.concatenate((pa_matrix, snp_mat), axis=1)\n",
    "# scaler = StandardScaler()\n",
    "# full_matrix = scaler.fit_transform(full_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d57cc4-21fb-4cf5-b0c8-b1662cda0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41458834/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated\n",
    "## No _ in the method name, please\n",
    "max_idx_amr = 14; # max value = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd563768-2443-4f0c-8032-e48f5590ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTZ\n",
      "CTX\n",
      "AMP\n",
      "AMX\n",
      "AMC\n",
      "TZP\n",
      "CXM\n",
      "CET\n",
      "GEN\n",
      "TBM\n",
      "TMP\n",
      "CIP\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2, max_idx_amr):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "    # Run unimodal gene\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(full_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(snp_mat, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaSnp', True, 'chi2')\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombine', False, 'mutual_info_classif', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombineScale', True, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombinehighGene', False, 'chi2', snp_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc13e5-f159-485f-912b-d7bcbd14905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.75 0.8  0.79]\n",
    "# [0.89 0.94 0.94]\n",
    "# [0.68 0.72 0.73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e240a7-18fa-47bc-812e-079eadd978a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "#     run_ML(pa_matrixPanPred.values, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPred' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb3bac-4e71-4839-9a70-2f920148fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate: + population structure\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# ps_matrixPanPred = populationstructure.loc[isolate_index]\n",
    "# combinematrixPanPred = np.concatenate((pa_matrixPanPred.values, ps_matrixPanPred.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8595a1-c4ac-4ec9-baa4-adea5c71d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaled_combinematrixPanPred = scaler.fit_transform(combinematrixPanPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1630b0-d1cd-4c84-b301-8f27e839b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "#     run_ML(scaled_combinematrixPanPred, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPredCombine' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e45cc9-d6e3-4b1b-a322-7141a3721d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
