{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ML methods on PanPred and panta outputs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from numpy import genfromtxt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbab2fdc-821c-4a48-9fd9-982cc7ddfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '_v6'  # Remove missing labels, and I = resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\", feature_selection = False, FS_method = 'mutual_info_classif', X2 = None):\n",
    "    base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred'+version\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.system('mkdir '+ base_dir)\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 2\n",
    "    n_folds = 5\n",
    "    n_samples = y.shape[0]\n",
    "    if X2 is not None:\n",
    "        print(\"Original shape of input:\", X.shape, X2.shape)\n",
    "    for i in range(n_loops):\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "            path_dir = base_dir +'/' + data_set + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "            print('Run: ', i, ', fold: ', fold)\n",
    "            X_train = X[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "            if False:\n",
    "                if i <= 0:\n",
    "                    print(\"Run feature selection\", 'method = ', FS_method)\n",
    "                if FS_method == 'mutual_info_classif':\n",
    "                    fs_fit = SelectKBest(mutual_info_classif, k=1000).fit(X_train, y_train)\n",
    "                elif FS_method == 'chi2':\n",
    "                    fs_fit = SelectKBest(chi2, k=1000).fit(X_train, y_train)\n",
    "                else:\n",
    "                    print(\"Please input correct feature selection method\")\n",
    "                X_train = fs_fit.transform(X_train)\n",
    "                X_test = fs_fit.transform(X_test)\n",
    "            if X2 is not None:\n",
    "                X2_train = X2[train_idx]\n",
    "                X2_test = X2[test_idx]\n",
    "                if feature_selection:\n",
    "                    fs2_fit = SelectKBest(chi2, k=20000).fit(X2_train, y_train)\n",
    "                    X2_train = fs2_fit.transform(X2_train)\n",
    "                    X2_test = fs2_fit.transform(X2_test)\n",
    "                X_train = np.append(X_train, X2_train, axis = 1)\n",
    "                X_test = np.append(X_test, X2_test, axis = 1)\n",
    "                # print('Scale the combine data')\n",
    "                # scaler = StandardScaler()\n",
    "                # X_train = scaler.fit_transform(X_train)\n",
    "                # X_test = scaler.fit_transform(X_test)\n",
    "                \n",
    "            # print(\"Standize the data\")\n",
    "            # Save the test true labels\n",
    "            np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "            if i <= 0 and fold <= 0:\n",
    "                print(\"n_samples: \", n_samples)\n",
    "                print(\"Reduced shape of the data: \", X_train.shape, X_test.shape)\n",
    "            print(test_idx[:10])\n",
    "\n",
    "#             # SVM\n",
    "#             methods.append('SVM')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_SVM_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Decision Tree\n",
    "#             methods.append('Decision Tree')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_DecisionTree_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # RF\n",
    "#             methods.append('RF')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_RandomForest_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Neural network\n",
    "#             methods.append('Neural network')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = MLPClassifier(alpha=1, max_iter=2000).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NeuralNet_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Adaboost\n",
    "#             methods.append('Adaboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Adaboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             ## K-NN \n",
    "#             methods.append('kNN')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NearestNeighbors_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Naive Bayes\n",
    "#             methods.append('NaiveBayes')\n",
    "#             print(methods[-1], end ='\\n')\n",
    "#             clf = GaussianNB().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NaiveBayes_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "   \n",
    "#             # Xgboost\n",
    "#             clf=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=500, objective='binary:logistic', booster='gbtree', use_label_encoder=False) #binary\n",
    "#             methods.append('Xgboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             XGB=clf.fit(X_train,y_train)\n",
    "#             y_predict=XGB.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Xgboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "            \n",
    "            # # GradientBoostingClassifier\n",
    "            # methods.append('Gradient Boost Decision Tree')\n",
    "            # print(methods[-1], end =', ')\n",
    "            # clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "            # y_predict = clf.predict(X_test)\n",
    "            # np.savetxt(path_dir + \"_GBDT_labels.csv\", y_predict, delimiter=\",\")\n",
    "            # score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "                  \n",
    "            # LightGBM\n",
    "            # if X2 is None:\n",
    "            #     clfG = lgb.LGBMClassifier()\n",
    "            # else:\n",
    "            #     clfG = lgb.LGBMClassifier(categorical_feature=list(range(1000,1000+10000)))\n",
    "            model = lgb.LGBMClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            methods.append('LightGBM')\n",
    "            print(methods[-1], end =', ')\n",
    "            # clfG.fit(X_train, y_train)\n",
    "            y_predict=model.predict(X_test) \n",
    "            np.savetxt(path_dir + \"_LightGBM_labels.csv\", y_predict, delimiter=\",\")\n",
    "            score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops*n_folds, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fad6e7-89f3-4c66-97b8-d15a2c7cf662",
   "metadata": {},
   "source": [
    "### Run PanPred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d4104a-03fe-4ab7-883b-2923866b7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata = pd.read_csv(\"PanPred/test_data/gene_presence_absence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2571b1ac-3dba-4fc9-bc8c-4386a58887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/Ecoli1936metafiles/PanPred_Metadata.csv')\n",
    "metadata = metadata.set_index(metadata['Isolate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8655ff5-829c-40dc-826a-b32623e25793",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessorygene =  pd.read_csv('PanPred/test_data/AccessoryGene.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9787bd8-54c7-4fbc-9bcd-d65b7cb12bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationstructure =  pd.read_csv('PanPred/test_data/PopulationStructure.csv_labelencoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8914f2ff-bf45-4c08-899f-f86867a79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accessorygene = accessorygene.loc[metadata['Isolate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da59d-d9be-433d-b3ae-1f99d0b1a15e",
   "metadata": {},
   "source": [
    "#### Run ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f790cd83-c663-4b27-b7a5-5c595f5115f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 14):\n",
    "#     y_class = metadata.iloc[:,idx].values\n",
    "#     print(metadata.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(1936)])\n",
    "#     run_ML(new_accessorygene.values, y, 'Ecoli1936','classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b18095a-41a5-47af-914b-b9028d944f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_accessorygene.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1ceff-dcc1-4f68-b5d8-709974fe9197",
   "metadata": {},
   "source": [
    "### Run Panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f93627-ebe5-4473-8e81-59e3dd0de1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_isolate = pd.read_csv('/data/hoan/amromics/prediction/data/Ecoli1936metafiles/sample_isolate.csv')\n",
    "sample_isolate.head(2)\n",
    "sample2isolate = {}\n",
    "for idx in range(len(sample_isolate.index)):\n",
    "    sample2isolate[sample_isolate.iloc[idx,0]+'.contig'] = sample_isolate.iloc[idx,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae607ee-2625-4af8-85e0-d16f8a5fe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936/gene_presence_absence.Rtab', sep='\\t', index_col=0).T\n",
    "pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936align_v4/gene_presence_absence.Rtab', sep='\\t', index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177913ea-ffd9-4ff0-aef7-d2827682908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_index = [sample2isolate[sample] for sample in pa_matrix.index]\n",
    "metadata_panta = metadata.loc[isolate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7e925b-53c5-410e-bb87-e04de6bb8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate</th>\n",
       "      <th>Year</th>\n",
       "      <th>CTZ</th>\n",
       "      <th>CTX</th>\n",
       "      <th>AMP</th>\n",
       "      <th>AMX</th>\n",
       "      <th>AMC</th>\n",
       "      <th>TZP</th>\n",
       "      <th>CXM</th>\n",
       "      <th>CET</th>\n",
       "      <th>GEN</th>\n",
       "      <th>TBM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>CIP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isolate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11658_4#1</th>\n",
       "      <td>11658_4#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657_5#1</th>\n",
       "      <td>11657_5#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Isolate    Year CTZ CTX AMP  AMX AMC TZP CXM CET GEN TBM TMP CIP\n",
       "Isolate                                                                      \n",
       "11658_4#1  11658_4#1  2006.0   S   S   S  NaN   S   S   R   S   S   S   S   S\n",
       "11657_5#1  11657_5#1  2006.0   S   S   R  NaN   R   S   S   S   S   S   R   R"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_panta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd9157e-b3ab-42e6-9517-ac9b931d6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_panta.to_csv(\"data/Ecoli1936metafiles/metadata_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54efcc1e-d9f7-46ef-b596-9660e0db5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(metadata_panta['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320278fc-6f12-42e8-982e-fc3af581b212",
   "metadata": {},
   "source": [
    "#### FS for presence-absence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644dd41c-b535-4f86-855d-9179d6ffe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "pa_matrix = sel.fit_transform(pa_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61843353-309e-401a-a0bf-5cd73ba7bf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 73473)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f40a7f4-202a-49a3-bd1c-159a783585bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pantaout_dir = '/data/hoan/amromics/prediction/output/pantaEcoli1936align_v4/'\n",
    "# snp_mat = genfromtxt(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.csv', delimiter=',')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.npy')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat.npy')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat_VT10.npy') # pantaVT10\n",
    "# snp_mat = np.load(pantaout_dir + 'coregenes.npy') #pantaCoreGene\n",
    "# snp_mat = np.load(pantaout_dir + 'pantaGFilterHighGeneNeighborVT5.npy') #pantaGFilterHighGeneNeighborVT5\n",
    "# snp_mat = np.load(pantaout_dir + 'highDegreeGenesEncodermat.npy') # pantaHighGene\n",
    "# snp_mat = np.load(pantaout_dir + 'differsite.npy') # pantaDifferSite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da91b2f-035b-4930-bbce-416794782ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snp_data = 'similarsitecolsum1pct.npy'\n",
    "# snp_data = 'pantaGFilterHighGeneNeighborVT5.npy'\n",
    "snp_data = 'genes_fold_0.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31dc7582-59ce-4440-9a44-cc9a4d92a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_mat = np.load(pantaout_dir + snp_data) # pantaDifferSite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06729c27-a793-4207-baeb-9bf07f73d528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 297728)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f4a4337-de69-4a02-9159-e2057f42d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if snp_data == 'similarsitecolsum1pct.npy':\n",
    "    panta_single = 'pantaSimSiteCS1pct'\n",
    "    panta_combine = 'pantaCombineSimSiteCS1pct'\n",
    "if snp_data == 'pantaGFilterHighGeneNeighborVT5.npy':\n",
    "    panta_single = 'pantaGFilterHighGeneNeighborVT5'\n",
    "    panta_combine = 'pantaCombineGFilterHighGeneNeighborVT5'\n",
    "if snp_data == 'genes_fold_0.npy':\n",
    "    panta_single = 'pantaGeneFold0'\n",
    "    panta_combine = 'pantaCombineGeneFold0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1183d7d4-b91b-4b19-b176-1f8572b7bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = metadata_panta.iloc[:,4].values\n",
    "def binary_label(y_class):\n",
    "    y_bin = []\n",
    "    nonenan_index = []\n",
    "    for i in range(len(y_class)):\n",
    "        if y_class[i]=='R' or y_class[i]=='I':\n",
    "            y_bin.append(1)\n",
    "            nonenan_index.append(i)\n",
    "        elif y_class[i]=='S':\n",
    "            y_bin.append(0)\n",
    "            nonenan_index.append(i)\n",
    "        else:\n",
    "            y_bin.append(y_class[i])\n",
    "    return np.array(y_bin), nonenan_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d57cc4-21fb-4cf5-b0c8-b1662cda0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41458834/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated\n",
    "## No _ in the method name, please\n",
    "max_idx_amr = 14; # max value = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd563768-2443-4f0c-8032-e48f5590ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTZ\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1652\n",
      "Reduced shape of the data:  (1321, 7639) (331, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 40 42]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.88]\n",
      "CTX\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1576\n",
      "Reduced shape of the data:  (1260, 7639) (316, 7639)\n",
      "[ 1  2  4  5  9 14 17 18 19 22]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 8 10 15 29 35 39 40 44 47 49]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 6 13 16 20 30 37 38 50 51 62]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  7 12 21 26 42 46 48 59]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 3  8 19 22 30 37 48 49 51 53]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6  9 10 12 27 34 35 41 47 58]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 2  5 11 13 16 17 23 26 32 33]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 0  1  4  7 14 18 28 29 31 36]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.94]\n",
      "AMP\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  562\n",
      "Reduced shape of the data:  (449, 7639) (113, 7639)\n",
      "[ 1 10 12 15 17 21 37 45 46 66]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 4  5  6  7  8 18 26 30 31 34]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 2 14 20 22 27 29 33 35 39 44]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 3 11 13 16 19 24 25 32 36 40]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[ 0  9 23 28 42 43 47 48 53 57]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  4  5  9 17 29 31 34 40]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 11 13 16 18 19 23 39 42 46]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1 12 14 27 38 44 51 53 69 73]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 8 10 21 24 28 32 33 35 45 48]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[ 2  7 15 20 22 25 26 30 36 37]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.86]\n",
      "AMX\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1090\n",
      "Reduced shape of the data:  (872, 7639) (218, 7639)\n",
      "[ 1  2  5 14 15 18 27 31 45 55]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 6  8  9 10 20 30 34 37 38 39]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 0  3 12 17 21 22 26 35 46 47]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 4  7 13 16 24 29 33 44 53 56]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 19 23 25 28 32 36 41 43 57]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 3  6  8 13 17 19 27 34 35 41]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 2  5 11 12 16 23 33 45 46 50]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 0  4  7  9 14 22 26 29 30 31]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 1 18 36 37 43 51 53 64 70 79]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[10 15 20 21 24 25 28 32 44 48]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.85]\n",
      "AMC\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1652\n",
      "Reduced shape of the data:  (1321, 7639) (331, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 40 42]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.71]\n",
      "TZP\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1648\n",
      "Reduced shape of the data:  (1318, 7639) (330, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 42 46]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.48]\n",
      "CXM\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1652\n",
      "Reduced shape of the data:  (1321, 7639) (331, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 40 42]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.82]\n",
      "CET\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  562\n",
      "Reduced shape of the data:  (449, 7639) (113, 7639)\n",
      "[ 1 10 12 15 17 21 37 45 46 66]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 4  5  6  7  8 18 26 30 31 34]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 2 14 20 22 27 29 33 35 39 44]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 3 11 13 16 19 24 25 32 36 40]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[ 0  9 23 28 42 43 47 48 53 57]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  4  5  9 17 29 31 34 40]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 11 13 16 18 19 23 39 42 46]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1 12 14 27 38 44 51 53 69 73]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 8 10 21 24 28 32 33 35 45 48]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[ 2  7 15 20 22 25 26 30 36 37]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.89]\n",
      "GEN\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1652\n",
      "Reduced shape of the data:  (1321, 7639) (331, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 40 42]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.86]\n",
      "TBM\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  562\n",
      "Reduced shape of the data:  (449, 7639) (113, 7639)\n",
      "[ 1 10 12 15 17 21 37 45 46 66]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 4  5  6  7  8 18 26 30 31 34]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 2 14 20 22 27 29 33 35 39 44]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 3 11 13 16 19 24 25 32 36 40]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[ 0  9 23 28 42 43 47 48 53 57]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  4  5  9 17 29 31 34 40]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 11 13 16 18 19 23 39 42 46]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1 12 14 27 38 44 51 53 69 73]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 8 10 21 24 28 32 33 35 45 48]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[ 2  7 15 20 22 25 26 30 36 37]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.8]\n",
      "TMP\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  562\n",
      "Reduced shape of the data:  (449, 7639) (113, 7639)\n",
      "[ 1 10 12 15 17 21 37 45 46 66]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 4  5  6  7  8 18 26 30 31 34]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[ 2 14 20 22 27 29 33 35 39 44]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 3 11 13 16 19 24 25 32 36 40]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[ 0  9 23 28 42 43 47 48 53 57]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  4  5  9 17 29 31 34 40]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 11 13 16 18 19 23 39 42 46]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1 12 14 27 38 44 51 53 69 73]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 8 10 21 24 28 32 33 35 45 48]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[ 2  7 15 20 22 25 26 30 36 37]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.88]\n",
      "CIP\n",
      "Run:  0 , fold:  0\n",
      "n_samples:  1652\n",
      "Reduced shape of the data:  (1321, 7639) (331, 7639)\n",
      "[ 4  5  9 14 17 18 19 22 31 34]\n",
      "LightGBM, Run:  0 , fold:  1\n",
      "[ 1  2  8 10 27 29 35 39 40 42]\n",
      "LightGBM, Run:  0 , fold:  2\n",
      "[13 15 16 30 37 51 60 62 65 68]\n",
      "LightGBM, Run:  0 , fold:  3\n",
      "[ 0  3  6  7 12 20 21 26 38 46]\n",
      "LightGBM, Run:  0 , fold:  4\n",
      "[11 23 24 25 28 32 33 36 41 43]\n",
      "LightGBM, Run:  1 , fold:  0\n",
      "[ 0  3  8 19 22 30 37 48 49 51]\n",
      "LightGBM, Run:  1 , fold:  1\n",
      "[ 6 12 27 34 35 41 45 47 56 62]\n",
      "LightGBM, Run:  1 , fold:  2\n",
      "[ 1  2  5  9 10 11 13 16 17 23]\n",
      "LightGBM, Run:  1 , fold:  3\n",
      "[ 4  7 14 18 28 29 33 36 40 42]\n",
      "LightGBM, Run:  1 , fold:  4\n",
      "[15 20 21 24 25 43 44 55 63 77]\n",
      "LightGBM, ['LightGBM']\n",
      "[0.97]\n"
     ]
    }
   ],
   "source": [
    "# for idx in range(2, 3):\n",
    "for idx in range(2, max_idx_amr):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    # y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))]) version _v5\n",
    "    y, nonenan_index = binary_label(y_class) # v6\n",
    "    pa_matrix_new = pa_matrix[nonenan_index, ]\n",
    "    y_new = y[nonenan_index]\n",
    "    snp_mat_new = snp_mat[nonenan_index,]\n",
    "    # Run unimodal gene\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(full_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(snp_mat, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaSnp', True, 'chi2')\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombine', False, 'mutual_info_classif', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombineScale', True, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombinehighGene', False, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'chi2', None)\n",
    "    # run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaVT10', False, 'chi2', None)\n",
    "    run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_single, False, 'chi2', None)\n",
    "    run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_combine, False, 'chi2', snp_mat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26e240a7-18fa-47bc-812e-079eadd978a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     y, nonenan_index = binary_label(y_class) # v6\n",
    "#     pa_matrixPanPred_new = pa_matrixPanPred.values[nonenan_index, ]\n",
    "#     y_new = y[nonenan_index]\n",
    "#     run_ML(pa_matrixPanPred_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPred' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cadb3bac-4e71-4839-9a70-2f920148fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate: + population structure\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# ps_matrixPanPred = populationstructure.loc[isolate_index]\n",
    "# combinematrixPanPred = np.concatenate((pa_matrixPanPred.values, ps_matrixPanPred.values), axis=1)\n",
    "# # combinematrixPanPred_new = \n",
    "# # scaler = StandardScaler()\n",
    "# # scaled_combinematrixPanPred = scaler.fit_transform(combinematrixPanPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d1630b0-d1cd-4c84-b301-8f27e839b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     # y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "#     # run_ML(scaled_combinematrixPanPred, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPredCombine' )\n",
    "#     y, nonenan_index = binary_label(y_class) # v6\n",
    "#     combinematrixPanPred_new = combinematrixPanPred[nonenan_index, ]\n",
    "#     y_new = y[nonenan_index]\n",
    "#     run_ML(combinematrixPanPred_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPredCombine' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e45cc9-d6e3-4b1b-a322-7141a3721d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
