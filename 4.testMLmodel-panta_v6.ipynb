{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run ML methods on PanPred and panta outputs \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from numpy import genfromtxt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbab2fdc-821c-4a48-9fd9-982cc7ddfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '_v9'  # Remove missing labels, and I = resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\", feature_selection = False, FS_method = 'mutual_info_classif', X2 = None):\n",
    "    # base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred'+version\n",
    "    base_dir = '/data/hoan/amromics/prediction/output/predPantaPanPred_v6'\n",
    "    # pantaout_dir = '/data/hoan/amromics/prediction/output/pantaSaPatric/'\n",
    "    if not os.path.isdir(base_dir):\n",
    "        os.system('mkdir '+ base_dir)\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 2\n",
    "    n_folds = 5\n",
    "    n_samples = y.shape[0]\n",
    "    if X2 is not None:\n",
    "        print(\"Original shape of input:\", X.shape, X2.shape)\n",
    "    for i in range(n_loops):\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "            path_dir = base_dir +'/' + data_set + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "            print('Run: ', i, ', fold: ', fold)\n",
    "            X_train = X[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "            if False:\n",
    "                if i <= 0:\n",
    "                    print(\"Run feature selection\", 'method = ', FS_method)\n",
    "                if FS_method == 'mutual_info_classif':\n",
    "                    fs_fit = SelectKBest(mutual_info_classif, k=1000).fit(X_train, y_train)\n",
    "                elif FS_method == 'chi2':\n",
    "                    fs_fit = SelectKBest(chi2, k=1000).fit(X_train, y_train)\n",
    "                else:\n",
    "                    print(\"Please input correct feature selection method\")\n",
    "                X_train = fs_fit.transform(X_train)\n",
    "                X_test = fs_fit.transform(X_test)\n",
    "            if X2 is not None:\n",
    "                X2_train = X2[train_idx]\n",
    "                X2_test = X2[test_idx]\n",
    "                if feature_selection:\n",
    "                    fs2_fit = SelectKBest(chi2, k=20000).fit(X2_train, y_train)\n",
    "                    X2_train = fs2_fit.transform(X2_train)\n",
    "                    X2_test = fs2_fit.transform(X2_test)\n",
    "                X_train = np.append(X_train, X2_train, axis = 1)\n",
    "                X_test = np.append(X_test, X2_test, axis = 1)\n",
    "                # print('Scale the combine data')\n",
    "                # scaler = StandardScaler()\n",
    "                # X_train = scaler.fit_transform(X_train)\n",
    "                # X_test = scaler.fit_transform(X_test)\n",
    "                \n",
    "            # print(\"Standize the data\")\n",
    "            # Save the test true labels\n",
    "            np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "            if i <= 0 and fold <= 0:\n",
    "                print(\"n_samples: \", n_samples)\n",
    "                print(\"Reduced shape of the data: \", X_train.shape, X_test.shape)\n",
    "            print(test_idx[:10])\n",
    "\n",
    "#             # SVM\n",
    "#             methods.append('SVM')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_SVM_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Decision Tree\n",
    "#             methods.append('Decision Tree')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_DecisionTree_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # RF\n",
    "#             methods.append('RF')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_RandomForest_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Neural network\n",
    "#             methods.append('Neural network')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = MLPClassifier(alpha=1, max_iter=2000).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NeuralNet_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Adaboost\n",
    "#             methods.append('Adaboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Adaboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             ## K-NN \n",
    "#             methods.append('kNN')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NearestNeighbors_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "\n",
    "#             # Naive Bayes\n",
    "#             methods.append('NaiveBayes')\n",
    "#             print(methods[-1], end ='\\n')\n",
    "#             clf = GaussianNB().fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_NaiveBayes_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "   \n",
    "#             # Xgboost\n",
    "#             clf=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=500, objective='binary:logistic', booster='gbtree', use_label_encoder=False) #binary\n",
    "#             methods.append('Xgboost')\n",
    "#             print(methods[-1], end =', ')\n",
    "#             XGB=clf.fit(X_train,y_train)\n",
    "#             y_predict=XGB.predict(X_test)\n",
    "#             np.savetxt(path_dir + \"_Xgboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "#             score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "            \n",
    "            # # GradientBoostingClassifier\n",
    "            # methods.append('Gradient Boost Decision Tree')\n",
    "            # print(methods[-1], end =', ')\n",
    "            # clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "            # y_predict = clf.predict(X_test)\n",
    "            # np.savetxt(path_dir + \"_GBDT_labels.csv\", y_predict, delimiter=\",\")\n",
    "            # score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "                  \n",
    "            # LightGBM\n",
    "            # if X2 is None:\n",
    "            #     clfG = lgb.LGBMClassifier()\n",
    "            # else:\n",
    "            #     clfG = lgb.LGBMClassifier(categorical_feature=list(range(1000,1000+10000)))\n",
    "            model = lgb.LGBMClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            methods.append('LightGBM')\n",
    "            print(methods[-1], end =', ')\n",
    "            # clfG.fit(X_train, y_train)\n",
    "            y_predict=model.predict(X_test) \n",
    "            np.savetxt(path_dir + \"_LightGBM_labels.csv\", y_predict, delimiter=\",\")\n",
    "            score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops*n_folds, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fad6e7-89f3-4c66-97b8-d15a2c7cf662",
   "metadata": {},
   "source": [
    "### Run PanPred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d4104a-03fe-4ab7-883b-2923866b7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata = pd.read_csv(\"PanPred/test_data/gene_presence_absence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2571b1ac-3dba-4fc9-bc8c-4386a58887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/Ecoli1936metafiles/PanPred_Metadata.csv')\n",
    "metadata = metadata.set_index(metadata['Isolate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8655ff5-829c-40dc-826a-b32623e25793",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessorygene =  pd.read_csv('PanPred/test_data/AccessoryGene.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9787bd8-54c7-4fbc-9bcd-d65b7cb12bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationstructure =  pd.read_csv('PanPred/test_data/PopulationStructure.csv_labelencoded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8914f2ff-bf45-4c08-899f-f86867a79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accessorygene = accessorygene.loc[metadata['Isolate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da59d-d9be-433d-b3ae-1f99d0b1a15e",
   "metadata": {},
   "source": [
    "#### Run ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f790cd83-c663-4b27-b7a5-5c595f5115f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 14):\n",
    "#     y_class = metadata.iloc[:,idx].values\n",
    "#     print(metadata.columns[idx])\n",
    "#     y = np.array([1 if y_class[i]=='R' else 0 for i in range(1936)])\n",
    "#     run_ML(new_accessorygene.values, y, 'Ecoli1936','classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b18095a-41a5-47af-914b-b9028d944f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_accessorygene.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1ceff-dcc1-4f68-b5d8-709974fe9197",
   "metadata": {},
   "source": [
    "### Run Panta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f93627-ebe5-4473-8e81-59e3dd0de1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_isolate = pd.read_csv('/data/hoan/amromics/prediction/data/Ecoli1936metafiles/sample_isolate.csv')\n",
    "sample_isolate.head(2)\n",
    "sample2isolate = {}\n",
    "for idx in range(len(sample_isolate.index)):\n",
    "    sample2isolate[sample_isolate.iloc[idx,0]+'.contig'] = sample_isolate.iloc[idx,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae607ee-2625-4af8-85e0-d16f8a5fe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936/gene_presence_absence.Rtab', sep='\\t', index_col=0).T\n",
    "pa_matrix = pd.read_csv('/data/hoan/amromics/prediction/output/pantaEcoli1936align'+version+'/gene_presence_absence.Rtab', sep='\\t', index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177913ea-ffd9-4ff0-aef7-d2827682908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate_index = [sample2isolate[sample] for sample in pa_matrix.index]\n",
    "metadata_panta = metadata.loc[isolate_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb7e925b-53c5-410e-bb87-e04de6bb8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate</th>\n",
       "      <th>Year</th>\n",
       "      <th>CTZ</th>\n",
       "      <th>CTX</th>\n",
       "      <th>AMP</th>\n",
       "      <th>AMX</th>\n",
       "      <th>AMC</th>\n",
       "      <th>TZP</th>\n",
       "      <th>CXM</th>\n",
       "      <th>CET</th>\n",
       "      <th>GEN</th>\n",
       "      <th>TBM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>CIP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isolate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11658_4#1</th>\n",
       "      <td>11658_4#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657_5#1</th>\n",
       "      <td>11657_5#1</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Isolate    Year CTZ CTX AMP  AMX AMC TZP CXM CET GEN TBM TMP CIP\n",
       "Isolate                                                                      \n",
       "11658_4#1  11658_4#1  2006.0   S   S   S  NaN   S   S   R   S   S   S   S   S\n",
       "11657_5#1  11657_5#1  2006.0   S   S   R  NaN   R   S   S   S   S   S   R   R"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_panta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd9157e-b3ab-42e6-9517-ac9b931d6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_panta.to_csv(\"data/Ecoli1936metafiles/metadata_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54efcc1e-d9f7-46ef-b596-9660e0db5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(metadata_panta['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320278fc-6f12-42e8-982e-fc3af581b212",
   "metadata": {},
   "source": [
    "#### FS for presence-absence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644dd41c-b535-4f86-855d-9179d6ffe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "pa_matrix = sel.fit_transform(pa_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61843353-309e-401a-a0bf-5cd73ba7bf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 73473)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f40a7f4-202a-49a3-bd1c-159a783585bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pantaout_dir = '/data/hoan/amromics/prediction/output/pantaEcoli1936align'+version+'/'\n",
    "# snp_mat = genfromtxt(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.csv', delimiter=',')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat_VarianceThreshold.npy')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat.npy')\n",
    "# snp_mat = np.load(pantaout_dir + 'amrlabelencodermat_VT10.npy') # pantaVT10\n",
    "# snp_mat = np.load(pantaout_dir + 'coregenes.npy') #pantaCoreGene\n",
    "# snp_mat = np.load(pantaout_dir + 'pantaGFilterHighGeneNeighborVT5.npy') #pantaGFilterHighGeneNeighborVT5\n",
    "# snp_mat = np.load(pantaout_dir + 'highDegreeGenesEncodermat.npy') # pantaHighGene\n",
    "# snp_mat = np.load(pantaout_dir + 'differsite.npy') # pantaDifferSite\n",
    "# snp_data = 'similarsitecolsum1pct.npy'\n",
    "# snp_data = 'pantaGFilterHighGeneNeighborVT5.npy'\n",
    "# snp_data = 'genes_fold_0.npy'\n",
    "# snp_data = 'topfeaturesbypresenceabsence_VT5.npy'\n",
    "# snp_data = 'topfeaturesbysimmat_VT5.npy'\n",
    "# snp_data = 'kmer_amr_count_mat_VT1.npy'\n",
    "# snp_data = 'kmer_amr_DNA_mat_VT5_top_features.npy'\n",
    "# snp_data = 'triple_AMR_matrix.npy'\n",
    "# snp_data = 'quintuple_AMR_matrix.npy'\n",
    "# snp_data = 'kmer_amr_neighbors_mat_VT5_top_features.npy'\n",
    "# snp_data = 'kmer_amr_neighbors_count_mat_VT5_top_features.npy'\n",
    "# snp_data = 'combine_kmer_matrix_loci.npy'\n",
    "# snp_data = 'combine_kmer_matrix_loci300.npy'\n",
    "# snp_data = 'combine_kmer_matrix_loci300K30.npy'\n",
    "# snp_data = 'combine_kmer_matrix_loci300K30TwoSides.npy'\n",
    "# snp_data = 'kmer_withincluster_amr_mat_VT5.npy'\n",
    "# snp_data = 'kmer_withincluster_amr_mat_VT1_newPan.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPan.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV6.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV7.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV8.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV9.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV10.npy'\n",
    "# snp_data = 'kmer_withincluster_amr_mat_VT1_newPanV9.npy'\n",
    "# snp_data = 'amrlabelencodermat_top10kgenes_v9.npy'\n",
    "# snp_data = 'kmer_amr_mat_VT1_newPanV9p2.npy'\n",
    "# snp_data = 'kmerDNANeighborPanV9.npy'\n",
    "# snp_data = 'kmerAADNANeighborPanV9.npy'\n",
    "# snp_data = 'kmerK5AADNANeighborPanV9.npy'\n",
    "# snp_data = 'combine_kmer_matrix_loci300K30TwoSidesPanv9.npy'\n",
    "snp_data = 'kmerK5AADNANeighborPanV8.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31dc7582-59ce-4440-9a44-cc9a4d92a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_mat = np.load(pantaout_dir + snp_data) # pantaDifferSite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06729c27-a793-4207-baeb-9bf07f73d528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1653, 297728)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a4337-de69-4a02-9159-e2057f42d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if snp_data == 'similarsitecolsum1pct.npy':\n",
    "    panta_single = 'pantaSimSiteCS1pct'\n",
    "    panta_combine = 'pantaCombineSimSiteCS1pct'\n",
    "if snp_data == 'pantaGFilterHighGeneNeighborVT5.npy':\n",
    "    panta_single = 'pantaGFilterHighGeneNeighborVT5'\n",
    "    panta_combine = 'pantaCombineGFilterHighGeneNeighborVT5'\n",
    "if snp_data == 'genes_fold_0.npy':\n",
    "    panta_single = 'pantaGeneFold0'\n",
    "    panta_combine = 'pantaCombineGeneFold0'\n",
    "if snp_data == 'topfeaturesbypresenceabsence_VT5.npy':\n",
    "    panta_single = 'pantaKmerTopGenePan'\n",
    "    panta_combine = 'pantaKmerCombineTopGenePan'\n",
    "if snp_data == 'topfeaturesbysimmat_VT5.npy':\n",
    "    panta_single = 'pantaKmerTopGeneSimMat'\n",
    "    panta_combine = 'pantaCombineKmerTopGeneSimMat'\n",
    "if snp_data == 'kmer_amr_count_mat_VT1.npy':\n",
    "    panta_single = 'pantaKmerCountVT1'\n",
    "    panta_combine = 'pantaCombineKmerCountVT1'\n",
    "if snp_data == 'kmer_amr_DNA_mat_VT5_top_features.npy':\n",
    "    panta_single = 'pantaKmerAMRDNA20VT5'\n",
    "    panta_combine = 'pantaCombineKmerAMRDNA20VT5'\n",
    "if snp_data == 'triple_AMR_matrix.npy':\n",
    "    panta_single = 'pantaTripleAMR'\n",
    "    panta_combine = 'pantaCombineTripleAMR'\n",
    "if snp_data == 'quintuple_AMR_matrix.npy':\n",
    "    panta_single = 'pantaQuintupleAMR'\n",
    "    panta_combine = 'pantaCombineQuintupleAMR'\n",
    "if snp_data == 'kmer_amr_neighbors_mat_VT5_top_features.npy':\n",
    "    panta_single = 'pantaKmerAMRNeighbor'\n",
    "    panta_combine = 'pantaCombineKmerAMRNeighbor'\n",
    "if snp_data == 'kmer_amr_neighbors_count_mat_VT5_top_features.npy':\n",
    "    panta_single = 'pantaKmerAMRNeighborCount'\n",
    "    panta_combine = 'pantaCombineKmerAMRNeighborCount'\n",
    "if snp_data == 'combine_kmer_matrix_loci.npy':\n",
    "    panta_single = 'pantaKmerAMRLoci'\n",
    "    panta_combine = 'pantaCombineKmerAMRLoci'\n",
    "if snp_data == 'combine_kmer_matrix_loci300.npy':\n",
    "    panta_single = 'pantaKmerAMRLoci300'\n",
    "    panta_combine = 'pantaCombineKmerAMRLoci300'\n",
    "if snp_data == 'combine_kmer_matrix_loci300K30.npy':\n",
    "    panta_single = 'pantaKmerAMRLoci300K30'\n",
    "    panta_combine = 'pantaCombineKmerAMRLoci300K30'\n",
    "if snp_data == 'combine_kmer_matrix_loci300K30TwoSides.npy':\n",
    "    panta_single = 'pantaKmerAMRLoci300K30TwoSides'\n",
    "    panta_combine = 'pantaCombineKmerAMRLoci300K30TwoSides'\n",
    "if snp_data ==  'kmer_withincluster_amr_mat_VT5.npy':\n",
    "    panta_single = 'pantaKmerAMRWithinGene'\n",
    "    panta_combine = 'pantaCombineKmerAMRWithinGene'\n",
    "if snp_data == 'kmer_withincluster_amr_mat_VT1_newPan.npy':\n",
    "    panta_single = 'pantaKmerAMRWithinGeneNewPan'\n",
    "    panta_combine = 'pantaCombineKmerAMRWithinGeneNewPan'\n",
    "if snp_data == 'kmer_amr_mat_VT1_newPan.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPan'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPan'\n",
    "if snp_data == 'kmer_amr_mat_VT1_newPanV6.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV6'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV6'\n",
    "if snp_data == 'kmer_amr_mat_VT1_newPanV7.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV7'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV7'\n",
    "if snp_data ==  'kmer_amr_mat_VT1_newPanV8.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV8'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV8'\n",
    "if snp_data ==  'kmer_amr_mat_VT1_newPanV9.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV9'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV9'\n",
    "if snp_data ==  'kmer_amr_mat_VT1_newPanV10.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV10'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV10'\n",
    "if snp_data ==  'kmer_withincluster_amr_mat_VT1_newPanV9.npy':\n",
    "    panta_single = 'pantaKmerAMRWithinGeneNewPanV9'\n",
    "    panta_combine = 'pantaCombineKmerAMRWithinGeneNewPanV9'\n",
    "if snp_data ==  'amrlabelencodermat_top10kgenes_v9.npy':\n",
    "    panta_single = 'pantaSNPsV9'\n",
    "    panta_combine = 'pantaCombineSNPsV9'\n",
    "if snp_data == 'kmer_amr_mat_VT1_newPanV9p2.npy':\n",
    "    panta_single = 'pantaKmerAMRNewPanV9p2'\n",
    "    panta_combine = 'pantaCombineKmerAMRNewPanV9p2'\n",
    "if snp_data == 'kmerDNANeighborPanV9.npy':\n",
    "    panta_single = 'pantaKmerDNANeighborPanV9'\n",
    "    panta_combine = 'pantaCombineKmerDNANeighborPanV9'\n",
    "if snp_data == 'kmerAADNANeighborPanV9.npy':\n",
    "    panta_single = 'pantaKmerAADNANeighborPanV9'\n",
    "    panta_combine = 'pantaCombineKmerAADNANeighborPanV9'\n",
    "if snp_data == 'kmerK5AADNANeighborPanV9.npy':\n",
    "    panta_single = 'pantaKmerK5AADNANeighborPanV9'\n",
    "    panta_combine = 'pantaCombineKmerK5AADNANeighborPanV9'\n",
    "if snp_data == 'combine_kmer_matrix_loci300K30TwoSidesPanv9.npy':\n",
    "    panta_single = 'pantaKmerLociPanV9'\n",
    "    panta_combine = 'pantaCombineKmerLociPanV9'\n",
    "if snp_data == 'kmerK5AADNANeighborPanV8.npy':\n",
    "    panta_single = 'pantaKmerK5AADNANeighborPanV8'\n",
    "    panta_combine = 'pantaCombineKmerK5AADNANeighborPanV8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183d7d4-b91b-4b19-b176-1f8572b7bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangraph.utils import binary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d57cc4-21fb-4cf5-b0c8-b1662cda0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41458834/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated\n",
    "## No _ in the method name, please\n",
    "max_idx_amr = 14; # max value = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd563768-2443-4f0c-8032-e48f5590ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, 3):\n",
    "for idx in range(2, max_idx_amr):\n",
    "    y_class = metadata_panta.iloc[:,idx].values\n",
    "    print(metadata_panta.columns[idx])\n",
    "    # y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))]) version _v5\n",
    "    y, nonenan_index = binary_label(y_class) # v6\n",
    "    pa_matrix_new = pa_matrix[nonenan_index, ]\n",
    "    y_new = y[nonenan_index]\n",
    "    snp_mat_new = snp_mat[nonenan_index,]\n",
    "    # Run unimodal gene\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(full_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'mutual_info_classif', None)\n",
    "    # run_ML(snp_mat, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaSnp', True, 'chi2')\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombine', False, 'mutual_info_classif', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombineScale', True, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaCombinehighGene', False, 'chi2', snp_mat)\n",
    "    # run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaPangenome', False, 'chi2', None)\n",
    "    # run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'pantaVT10', False, 'chi2', None)\n",
    "    run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_single, False, 'chi2', None)\n",
    "    # run_ML(snp_mat_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], \"pantaNewPanV7\", False, 'chi2', None)\n",
    "    run_ML(pa_matrix_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx], panta_combine, False, 'chi2', snp_mat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7975a2b1-7fd5-48e5-87f0-371eaf223c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     y, nonenan_index = binary_label(y_class) # v6\n",
    "#     pa_matrixPanPred_new = pa_matrixPanPred.values[nonenan_index, ]\n",
    "#     y_new = y[nonenan_index]\n",
    "#     run_ML(pa_matrixPanPred_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPred' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36c78b5-8a76-444e-b713-64120e5e308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/data/hoan/amromics/prediction/data/PanPredMatrix.npy', pa_matrixPanPred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de48fab-96ac-448c-944f-cee0b131785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run PanPred on panta isolate: + population structure\n",
    "# pa_matrixPanPred = accessorygene.loc[isolate_index]\n",
    "# ps_matrixPanPred = populationstructure.loc[isolate_index]\n",
    "# combinematrixPanPred = np.concatenate((pa_matrixPanPred.values, ps_matrixPanPred.values), axis=1)\n",
    "# # combinematrixPanPred_new = \n",
    "# # scaler = StandardScaler()\n",
    "# # scaled_combinematrixPanPred = scaler.fit_transform(combinematrixPanPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9952968-90a1-4c2f-bb9a-54a9910114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/data/hoan/amromics/prediction/data/PanPredPopulationStructure.npy', ps_matrixPanPred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d1630b0-d1cd-4c84-b301-8f27e839b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(2, max_idx_amr):\n",
    "#     y_class = metadata_panta.iloc[:,idx].values\n",
    "#     print(metadata_panta.columns[idx])\n",
    "#     # y = np.array([1 if y_class[i]=='R' else 0 for i in range(len(y_class))])\n",
    "#     # run_ML(scaled_combinematrixPanPred, y, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPredCombine' )\n",
    "#     y, nonenan_index = binary_label(y_class) # v6\n",
    "#     combinematrixPanPred_new = combinematrixPanPred[nonenan_index, ]\n",
    "#     y_new = y[nonenan_index]\n",
    "#     run_ML(combinematrixPanPred_new, y_new, 'Ecoli1936'+'_'+metadata_panta.columns[idx],'PanPredCombine' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e45cc9-d6e3-4b1b-a322-7141a3721d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
