{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76b25e8-cb6d-4c6f-ba11-7d540e9a7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ML on all PanPred outputs\n",
    "## Run ML methods    \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8943e80e-ebca-4b41-90d7-61a777fac9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29670640-adab-40ab-b23c-c1f6d30113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(X, y, data_set, approach=\"Default\"):\n",
    "    score = []\n",
    "    methods = []\n",
    "    n_loops = 10\n",
    "    n_samples = y.shape[0]\n",
    "    for i in range(n_loops):\n",
    "        path_dir = '/data/hoan/amromics/prediction/output/PanPred/' + data_set + '_run_'+str(i)+'_'+approach\n",
    "        print('Run: ', i)\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        # print(X_train.shape, X_test.shape)\n",
    "        random.seed(i)\n",
    "        print(\"n_samples: \", n_samples)\n",
    "        train_idx = random.sample(range(n_samples), int(n_samples*0.8))\n",
    "        test_idx = [i for i in range(n_samples) if i not in train_idx]\n",
    "        print(train_idx[:10])\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test = y[test_idx]\n",
    "        # Save the test true labels\n",
    "        np.savetxt(path_dir + \"_test_true_labels.csv\", y_test, delimiter=\",\")\n",
    "        print(X_train.shape, X_test.shape)\n",
    "        \n",
    "        # SVM\n",
    "        methods.append('SVM')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        np.savetxt(path_dir + \"_SVM_labels.csv\", y_predict, delimiter=\",\")\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "       \n",
    "        # Decision Tree\n",
    "        methods.append('Decision Tree')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_DecisionTree_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # RF\n",
    "        methods.append('RF')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1).fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        np.savetxt(path_dir + \"_RandomForest_labels.csv\", y_predict, delimiter=\",\")\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # Neural network\n",
    "        methods.append('Neural network')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = MLPClassifier(alpha=1, max_iter=2000).fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_test)\n",
    "        np.savetxt(path_dir + \"_NeuralNet_labels.csv\", y_predict, delimiter=\",\")\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # Adaboost\n",
    "        methods.append('Adaboost')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = AdaBoostClassifier().fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_Adaboost_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # GradientBoostingClassifier\n",
    "        methods.append('Gradient Boost Decision Tree')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_GBDT_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        ## K-NN \n",
    "        methods.append('kNN')\n",
    "        print(methods[-1], end =', ')\n",
    "        clf = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_NearestNeighbors_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "        # Naive Bayes\n",
    "        methods.append('NaiveBayes')\n",
    "        print(methods[-1], end ='\\n')\n",
    "        clf = GaussianNB().fit(X_train, y_train)\n",
    "        np.savetxt(path_dir + \"_NaiveBayes_labels.csv\", y_predict, delimiter=\",\")\n",
    "        y_predict = clf.predict(X_test)\n",
    "        score.append(f1_score(y_predict, y_test, average='macro'))\n",
    "        \n",
    "    # Print statistics\n",
    "    n_methods = len(set(methods))\n",
    "    score_np = np.array(score)\n",
    "    # Each column is a method\n",
    "    print(methods[:n_methods])\n",
    "    average_score = np.mean(score_np.reshape((n_loops, n_methods)), axis=0)\n",
    "    print(np.round(average_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f69fa1-e777-4c7a-9a84-af04717355da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata = pd.read_csv(\"PanPred/test_data/gene_presence_absence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a41d179-2646-4232-86a0-5a0a4b32a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2571b1ac-3dba-4fc9-bc8c-4386a58887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('PanPred/test_data/Metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18176ab1-dda8-4689-8c07-fd19c3d0be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate</th>\n",
       "      <th>Year</th>\n",
       "      <th>CTZ</th>\n",
       "      <th>CTX</th>\n",
       "      <th>AMP</th>\n",
       "      <th>AMX</th>\n",
       "      <th>AMC</th>\n",
       "      <th>TZP</th>\n",
       "      <th>CXM</th>\n",
       "      <th>CET</th>\n",
       "      <th>GEN</th>\n",
       "      <th>TBM</th>\n",
       "      <th>TMP</th>\n",
       "      <th>CIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11657_5#10</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11657_5#11</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11657_5#12</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11657_5#13</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11657_5#14</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Isolate    Year CTZ CTX AMP  AMX AMC TZP CXM CET GEN TBM TMP CIP\n",
       "0  11657_5#10  2010.0   S   S   S  NaN   S   S   S   S   S   S   S   S\n",
       "1  11657_5#11  2010.0   S   S   R  NaN   R   S   S   S   S   S   R   R\n",
       "2  11657_5#12  2010.0   S   S   S  NaN   S   S   S   S   S   S   S   S\n",
       "3  11657_5#13  2010.0   S   S   R  NaN   R   S   S   S   S   S   S   R\n",
       "4  11657_5#14  2010.0   S   S   R  NaN   S   S   S   S   S   S   R   S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bfedba5-11ae-40aa-adcd-cf445cd2bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessorygene =  pd.read_csv('PanPred/test_data/AccessoryGene.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3195e2c-6081-47ee-8836-1aff8ae07b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationstructure =  pd.read_csv('PanPred/test_data/PopulationStructure.csv_labelencoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8914f2ff-bf45-4c08-899f-f86867a79c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accessorygene = accessorygene.loc[metadata['Isolate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da59d-d9be-433d-b3ae-1f99d0b1a15e",
   "metadata": {},
   "source": [
    "### Run ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f790cd83-c663-4b27-b7a5-5c595f5115f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2, 14):\n",
    "    y_class = metadata.iloc[:,idx].values\n",
    "    print(metadata.columns[idx])\n",
    "    y = np.array([1 if y_class[i]=='R' else 0 for i in range(1936)])\n",
    "    run_ML(new_accessorygene.values, y, 'Ecoli1936','classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b18095a-41a5-47af-914b-b9028d944f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTZ'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c8586-1732-454c-a05a-c1676edbc636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
